{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import logging\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedStratifiedKFold, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoE_Binning(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):  # no *args or *kargs\n",
    "        self.woe_grade = None\n",
    "        self.woe_home = None\n",
    "        self.woe_verStatus = None\n",
    "        self.woe_purpose = None\n",
    "        self.woe_term = None\n",
    "        self.woe_int_rate = None\n",
    "        self.woe_annInc = None\n",
    "        self.woe_dti = None\n",
    "        self.woe_revolUtil = None\n",
    "        self.woe_outPrncp = None\n",
    "        self.woe_totalPymnt = None\n",
    "        self.woe_totalRev = None\n",
    "        self.woe_mthsECL = None\n",
    "        self.woe_mthsID = None\n",
    "        self.woe_mthsLCP = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        logging.basicConfig(filename='./app.log', filemode='w',\n",
    "                            format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S', level=logging.INFO)\n",
    "        newX = X.copy()\n",
    "        # grade woe calculation\n",
    "        self.woe_grade = self.woe(X, 'grade', y)\n",
    "\n",
    "        # home_ownership woe calculation\n",
    "        self.woe_home = self.woe(X, 'home_ownership', y)\n",
    "\n",
    "        # verification_status woe calculation\n",
    "        self.woe_verStatus = self.woe(X, 'verification_status', y)\n",
    "\n",
    "        # purpose woe calculation\n",
    "        self.woe_purpose = self.woe(X, 'purpose', y)\n",
    "\n",
    "        # term woe calculation\n",
    "        self.woe_term = self.woe(X, 'term', y)\n",
    "\n",
    "        # int_rate woe calculation\n",
    "        # fine-classing using the 'cut' method, given the large number of unique values\n",
    "        newX['int_rate_factor'] = pd.cut(newX['int_rate'], 50, right=False)\n",
    "        # Process 'int_rate_factor' column through woe_ordered_continuous and plot_by_woe functions\n",
    "        self.woe_int_rate = self.woe(newX, 'int_rate_factor', y)\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_int_rate.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_int_rate.index[0].right, closed='left')\n",
    "        self.woe_int_rate = self.woe_int_rate.reset_index(\n",
    "        )[['int_rate_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_int_rate['int_rate_factor'][0] = iv_start\n",
    "        self.woe_int_rate['int_rate_factor'][-1] = iv_end\n",
    "        self.woe_int_rate = pd.DataFrame(self.woe_int_rate)\n",
    "\n",
    "        # annual_inc woe calculation\n",
    "        # Initial examination shows that there are too few individuals with large income (up to $75m!!) and too many with small income.\n",
    "        # Since 95.6% of observations have income < 151,858, we will have one category for more than 150K, and we are going to apply our approach to determine\n",
    "        # the categories of everyone with 150k or less.\n",
    "        new_X_temp = newX[newX['annual_inc'] <= 150500].copy()\n",
    "        # fine-classing again\n",
    "        new_X_temp['annual_inc_factor'] = pd.cut(new_X_temp['annual_inc'], 12)\n",
    "        # make sure to select only the relevant indexes in the target column\n",
    "        self.woe_annInc = self.woe(new_X_temp, 'annual_inc_factor', y[new_X_temp.index])\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_annInc.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_annInc.index[0].right, closed='left')\n",
    "        self.woe_annInc = self.woe_annInc.reset_index()[['annual_inc_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_annInc['annual_inc_factor'][0] = iv_start\n",
    "        self.woe_annInc['annual_inc_factor'][-1] = iv_end\n",
    "        self.woe_annInc = pd.DataFrame(self.woe_annInc)\n",
    "\n",
    "        # dti woe calculation\n",
    "        # fine-classing\n",
    "        newX['dti_factor'] = pd.cut(newX['dti'], 10)\n",
    "        # Process 'dti_factor' column through woe_ordered_continuous and plot_by_woe functions\n",
    "        self.woe_dti = self.woe(newX, 'dti_factor', y)\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_dti.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_dti.index[0].right, closed='left')\n",
    "        self.woe_dti = self.woe_dti.reset_index()[['dti_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_dti['dti_factor'][0] = iv_start\n",
    "        self.woe_dti['dti_factor'][-1] = iv_end\n",
    "        self.woe_dti = pd.DataFrame(self.woe_dti)\n",
    "\n",
    "        # revol_util woe calculation\n",
    "        # Initial examination shows that there are some obs with utilization of >1 times which should be very rare, so we will filter them out first\n",
    "        new_X_temp = newX[newX['revol_util'] <= 1].copy()\n",
    "        # fine-classing\n",
    "        new_X_temp['revol_util_factor'] = pd.cut(new_X_temp['revol_util'], 10)\n",
    "        # preprocess 'revol_util'\n",
    "        self.woe_revolUtil = self.woe(new_X_temp, 'revol_util_factor', y[new_X_temp.index])\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_revolUtil.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_revolUtil.index[0].right, closed='left')\n",
    "        self.woe_revolUtil = self.woe_revolUtil.reset_index()[['revol_util_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_revolUtil['revol_util_factor'][0] = iv_start\n",
    "        self.woe_revolUtil['revol_util_factor'][-1] = iv_end\n",
    "        self.woe_revolUtil = pd.DataFrame(self.woe_revolUtil)\n",
    "\n",
    "        # out_prncp woe calculation\n",
    "        # Here we do fine-classing: using the 'cut' method, we split the variable into 26 categories by its values.\n",
    "        newX['out_prncp_factor'] = pd.cut(newX['out_prncp'], 26)\n",
    "        # We calculate weight of evidence.\n",
    "        self.woe_outPrncp = self.woe(newX, 'out_prncp_factor', y)\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_outPrncp.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_outPrncp.index[0].right, closed='left')\n",
    "        self.woe_outPrncp = self.woe_outPrncp.reset_index()[['out_prncp_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_outPrncp['out_prncp_factor'][0] = iv_start\n",
    "        self.woe_outPrncp['out_prncp_factor'][-1] = iv_end\n",
    "        self.woe_outPrncp = pd.DataFrame(self.woe_outPrncp)\n",
    "\n",
    "        # total_pymnt woe calculation\n",
    "        # Initial examination shows that there are vey few obs with >25,000 which should be very rare, so we will filter them out first\n",
    "        new_X_temp = X[X['total_pymnt'] <= 30000].copy()\n",
    "        # fine-classing\n",
    "        new_X_temp['total_pymnt_factor'] = pd.cut(new_X_temp['total_pymnt'], 20)\n",
    "        # preprocess 'total_pymnt'\n",
    "        self.woe_totalPymnt = self.woe(new_X_temp, 'total_pymnt_factor', y[new_X_temp.index])\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_totalPymnt.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_totalPymnt.index[0].right, closed='left')\n",
    "        self.woe_totalPymnt = self.woe_totalPymnt.reset_index()[['total_pymnt_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_totalPymnt['total_pymnt_factor'][0] = iv_start\n",
    "        self.woe_totalPymnt['total_pymnt_factor'][-1] = iv_end\n",
    "        self.woe_totalPymnt = pd.DataFrame(self.woe_totalPymnt)\n",
    "\n",
    "        # total_rev_hi_lim woe calculation\n",
    "        # initial examination reveals very few obs > 79,780, we will filter them out first\n",
    "        new_X_temp = newX[newX['total_rev_hi_lim'] <= 79750].copy()\n",
    "        # fine-classing\n",
    "        new_X_temp['total_rev_hi_lim_factor'] = pd.cut(new_X_temp['total_rev_hi_lim'], 25)\n",
    "        # preprocess\n",
    "        self.woe_totalRev = self.woe(new_X_temp, 'total_rev_hi_lim_factor', y[new_X_temp.index])\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_totalRev.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_totalRev.index[0].right, closed='left')\n",
    "        self.woe_totalRev = self.woe_totalRev.reset_index()[['total_rev_hi_lim_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_totalRev['total_rev_hi_lim_factor'][0] = iv_start\n",
    "        self.woe_totalRev['total_rev_hi_lim_factor'][-1] = iv_end\n",
    "        self.woe_totalRev = pd.DataFrame(self.woe_totalRev)\n",
    "\n",
    "        # mths_since_earliest_cr_line woe calculation\n",
    "        # fine-classing\n",
    "        newX['mths_since_earliest_cr_line_factor'] = pd.cut(newX['mths_since_earliest_cr_line'], 50)\n",
    "        # preprocess\n",
    "        self.woe_mthsECL = self.woe(newX, 'mths_since_earliest_cr_line_factor', y)\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_mthsECL.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_mthsECL.index[0].right, closed='left')\n",
    "        self.woe_mthsECL = self.woe_mthsECL.reset_index()[['mths_since_earliest_cr_line_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_mthsECL['mths_since_earliest_cr_line_factor'][0] = iv_start\n",
    "        self.woe_mthsECL['mths_since_earliest_cr_line_factor'][-1] = iv_end\n",
    "        self.woe_mthsECL = pd.DataFrame(self.woe_mthsECL)\n",
    "\n",
    "        # mths_since_issue_d woe calculation\n",
    "        # fine-classing\n",
    "        newX['mths_since_issue_d_factor'] = pd.cut(newX['mths_since_issue_d'], 24)\n",
    "        # preprocess\n",
    "        self.woe_mthsID = self.woe(newX, \"mths_since_issue_d_factor\", y)\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_mthsID.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_mthsID.index[0].right, closed='left')\n",
    "        self.woe_mthsID = self.woe_mthsID.reset_index()[['mths_since_issue_d_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_mthsID['mths_since_issue_d_factor'][0] = iv_start\n",
    "        self.woe_mthsID['mths_since_issue_d_factor'][-1] = iv_end\n",
    "        self.woe_mthsID = pd.DataFrame(self.woe_mthsID)\n",
    "\n",
    "        # mths_since_last_credit_pull_d\n",
    "        # filter out all values > 75 given the low obs\n",
    "        #X_train_prepr_temp = X_train_prepr[X_train_prepr['mths_since_last_credit_pull_d'] <= 75].copy()\n",
    "        # Here we do fine-classing: using the 'cut' method, we split the variable into 25 categories\n",
    "        newX['mths_since_last_credit_pull_d_factor'] = pd.cut(newX['mths_since_last_credit_pull_d'], 10)\n",
    "        # Calculate WoE\n",
    "        self.woe_mthsLCP = self.woe(newX, \"mths_since_last_credit_pull_d_factor\", y[newX.index])\n",
    "        # Manipulation to include extreme bounds (0, infinity)\n",
    "        iv_end = pd.Interval(left=self.woe_mthsLCP.index[-1].left, right=np.inf, closed='left')\n",
    "        iv_start = pd.Interval(left=0, right=self.woe_mthsLCP.index[0].right, closed='left')\n",
    "        self.woe_mthsLCP = self.woe_mthsLCP.reset_index()[['mths_since_last_credit_pull_d_factor', 'woe']].to_dict(orient='list')\n",
    "        self.woe_mthsLCP['mths_since_last_credit_pull_d_factor'][0] = iv_start\n",
    "        self.woe_mthsLCP['mths_since_last_credit_pull_d_factor'][-1] = iv_end\n",
    "        self.woe_mthsLCP = pd.DataFrame(self.woe_mthsLCP)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        newX = X.copy()\n",
    "\n",
    "        # grade Processing\n",
    "        newX.replace({'grade': self.woe_grade[['woe']].to_dict()['woe']}, inplace=True)\n",
    "\n",
    "        # home_ownership processing\n",
    "        newX.replace({'home_ownership': self.woe_home[['woe']].to_dict()['woe']}, inplace=True)\n",
    "\n",
    "        # verification_status processing\n",
    "        newX.replace({'verification_status': self.woe_verStatus[['woe']].to_dict()['woe']}, inplace=True)\n",
    "\n",
    "        # purpose processing\n",
    "        newX.replace({'purpose': self.woe_purpose[['woe']].to_dict()['woe']}, inplace=True)\n",
    "\n",
    "        # term processing\n",
    "        newX.replace({'term': self.woe_term[['woe']].to_dict()['woe']}, inplace=True)\n",
    "\n",
    "        # int_rate processing\n",
    "        logging.info('int_rate processing...started')\n",
    "        newX['int_rate'] = self.replace_woe(newX['int_rate'], self.woe_int_rate, 'int_rate_factor')\n",
    "        logging.info('int_rate processing...end')\n",
    "\n",
    "        # annual_inc processing\n",
    "        logging.info('annual_inc processing...started')\n",
    "        newX['annual_inc'] = self.replace_woe(newX['annual_inc'], self.woe_annInc, 'annual_inc_factor')\n",
    "        logging.info('annual_inc processing...end')\n",
    "\n",
    "        # dti processing\n",
    "        logging.info('dti processing...started')\n",
    "        newX['dti'] = self.replace_woe(newX['dti'], self.woe_dti, 'dti_factor')\n",
    "        logging.info('dti processing...end')\n",
    "\n",
    "        # revol_util processing\n",
    "        logging.info('revol_util processing...started')\n",
    "        newX['revol_util'] = self.replace_woe(newX['revol_util'], self.woe_revolUtil, 'revol_util_factor')\n",
    "        logging.info('revol_util processing...end')\n",
    "\n",
    "        # out_prncp processing\n",
    "        logging.info('out_prncp processing...started')\n",
    "        newX['out_prncp'] = self.replace_woe(newX['out_prncp'], self.woe_outPrncp, 'out_prncp_factor')\n",
    "        logging.info('out_prncp processing...end')\n",
    "\n",
    "        # total_pymnt processing\n",
    "        logging.info('total_pymnt processing...started')\n",
    "        newX['total_pymnt'] = self.replace_woe(newX['total_pymnt'], self.woe_totalPymnt, 'total_pymnt_factor')\n",
    "        logging.info('total_pymnt processing...end')\n",
    "\n",
    "        # total_rev_hi_lim\n",
    "        logging.info('total_rev_hi_lim...started')\n",
    "        newX['total_rev_hi_lim'] = self.replace_woe(newX['total_rev_hi_lim'], self.woe_totalRev, 'total_rev_hi_lim_factor')\n",
    "        logging.info('total_rev_hi_lim...end')\n",
    "\n",
    "        # mths_since_earliest_cr_line\n",
    "        logging.info('mths_since_earliest_cr_line...started')\n",
    "        newX['mths_since_earliest_cr_line'] = self.replace_woe(newX['mths_since_earliest_cr_line'], self.woe_mthsECL, 'mths_since_earliest_cr_line_factor')\n",
    "        logging.info('mths_since_earliest_cr_line...end')\n",
    "\n",
    "        # mths_since_issue_d\n",
    "        logging.info('mths_since_issue_d...started')\n",
    "        newX['mths_since_issue_d'] = self.replace_woe(newX['mths_since_issue_d'], self.woe_mthsID, 'mths_since_issue_d_factor')\n",
    "        logging.info('mths_since_issue_d...end')\n",
    "\n",
    "        # mths_since_last_credit_pull_d\n",
    "        logging.info('mths_since_last_credit_pull_d...started')\n",
    "        newX['mths_since_last_credit_pull_d_factor'] = self.replace_woe(newX['mths_since_last_credit_pull_d'], self.woe_mthsLCP, 'mths_since_last_credit_pull_d_factor')\n",
    "        logging.info('mths_since_last_credit_pull_d...end')\n",
    "\n",
    "        return newX\n",
    "\n",
    "    def woe(self, df, cat_variabe_name, y_df):\n",
    "        \"\"\"\n",
    "        woe(weight of evidence) function\n",
    "        \"\"\"\n",
    "\n",
    "        df = pd.concat([df[cat_variabe_name], y_df], axis=1)\n",
    "        df_woe_iv = pd.crosstab(df[cat_variabe_name], df['good_bad'], normalize='columns').assign(\n",
    "            woe=lambda dfx: np.log(dfx[1]/dfx[0])).assign(iv=lambda dfx: np.sum(dfx['woe']*(dfx[1]-dfx[0])))\n",
    "        return df_woe_iv\n",
    "\n",
    "    def replace_woe(self, col, woe_sheet, name):\n",
    "        woe_t = []\n",
    "        arr_iv = pd.arrays.IntervalArray(woe_sheet[name], closed='left')\n",
    "        for i in col.values:\n",
    "            idx = np.argwhere(arr_iv.contains(i)).ravel()[0]\n",
    "            woe_t.append(woe_sheet.iloc[idx]['woe'])\n",
    "        return woe_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/loan-data/loan_data_2007_2014.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column based on the loan_status column that will be our target variable\n",
    "data['good_bad'] = np.where(data.loc[:, 'loan_status'].isin(['Charged Off', 'Default', 'Late (31-120 days)',\n",
    "                                                             'Does not meet the credit policy. Status:Charged Off']), 0, 1)\n",
    "# Drop the original 'loan_status' column\n",
    "data.drop(columns=['loan_status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.mean(axis=0), inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('good_bad', axis=1)[['grade', 'home_ownership', 'verification_status', 'purpose', 'term', 'int_rate', 'annual_inc', 'dti', 'revol_util',\n",
    "                                   'out_prncp', 'total_pymnt', 'total_rev_hi_lim', 'mths_since_earliest_cr_line', 'mths_since_issue_d', 'mths_since_last_credit_pull_d']]\n",
    "y = data['good_bad']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = joblib.load('./binning.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = num_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = num_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = cv = RepeatedStratifiedKFold(n_splits=5, random_state=42, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'n_estimators': range(50, 400, 50),\n",
    "    'objective': ['binary:logistic'],\n",
    "    'booster': ['dart', 'gbtree'],\n",
    "    'eta': [0.05, 0.1],\n",
    "    'verbosity': [2],\n",
    "    'tree_method': ['hist']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(eval_metric='error', use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model, xgb_param_grid, scoring=\"accuracy\", n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.errorbar(xgb_param_grid['n_estimators'], means, yerr=stds)\n",
    "plt.title(\"XGBoost n_estimators vs Log Loss\")\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.savefig('n_estimators.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc517702a83f00180aeadc3cce33d431d613f104256a96e294943db4b61bf09d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('fin': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
